{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjWFmzDfw1gO"
   },
   "source": [
    "## Task 1: News Topic Classifier Using BERT\n",
    "Problem Statement & Objective: Develop an NLP model to classify news headlines into four categories (World, Sports, Business, Sci/Tech) using a Transformer-based architecture.\n",
    "\n",
    "Dataset Loading & Preprocessing: Used the AG News Dataset. Preprocessing involved tokenization using BertTokenizer, padding, and truncation to a maximum length of 128 tokens for computational efficiency.\n",
    "\n",
    "Model Development & Training: Fine-tuned bert-base-uncased using the Hugging Face Trainer API. Optimized with fp16 mixed precision and a learning rate of 2e-5.\n",
    "\n",
    "Evaluation Metrics: Achieved high performance measured via Accuracy and Weighted F1-score.\n",
    "\n",
    "Visualizations: Training logs showing the decrease in loss and improvement in accuracy per epoch.\n",
    "\n",
    "Final Summary / Insights: Transformers like BERT outperform traditional RNNs because they capture bidirectional context, making them highly effective for short-text classification like headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I7wHBqjnOWd"
   },
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wm2Ag4aUnKUQ",
    "outputId": "58b8c224-5c68-4bd7-fe10-32832a6d14c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
      "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.9)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
      "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.6\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate accelerate scikit-learn gradio torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grfVZ0atnUZ2"
   },
   "source": [
    "## Tokenization and Preprocessing as well as Fine-tune the bert-base-uncased Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "32075235f0b747c5847ba5572cf46919",
      "4db416aad44a4591a2c46b4b1a445a91",
      "34a89fb9d3cb436e84b0ac269c37020a",
      "8ec750fc8d964fadba88204d049b442e",
      "82c460d581784eb683d74f78a11e2f51",
      "ba20a18f372943d683bcaa2eb56f2362",
      "061dd01eef394d5f91e45d7f0cce4356",
      "74e63184f8bc43aca770857c41e6320d",
      "a63b94043f8a47fbb4560f01ff6fc736",
      "9132d4830f7e49949f073869f915835e",
      "1e31bafeb93d4d97af13a2e0cf009f14",
      "7baab8e137804d22a32cf250199eb9b6",
      "02522ccd28cf475e81230a8bb5b58747",
      "8690088294d14f1c926ac706cce42809",
      "b0e3cbb55ade4c35869cc02e86be3dd0",
      "09abf2ed99b1428d9eac5818f57f98ee",
      "fbb0078580e34cbe93f0bca3cfaa93e2",
      "266c1f99dfff4ef1aaca4e9dcf6a4e2a",
      "c546888838b44909a692e654cda3d4f9",
      "248aa05982204bbca0199a30988c933c",
      "2942124350974d3780a83438bed2a4cf",
      "471f1d22c2054808895162662ebcafa4",
      "dcd5d143481545c9bbd775be99c7cf21",
      "5e3a5f4cc4f44b6d9de1d1e3cb69a08c",
      "e20f634159764416a8a90e09557044ee",
      "f16326491e2a4ee0b27ba8a3de815e70",
      "e8de0272ce70410eb0a3a42410162684",
      "30ee3adc796a499e9d2cbcdb68642aa5",
      "01681c1a240747bd9c4b5cb253528f2a",
      "d4021bd727fc4a9e9f80a0b01a971af3",
      "376ea41b2c2944308abb69c0d1025642",
      "641f4e347aba45cd99a8b809bd5addc4",
      "d266b0be4da6494ca5fbc1c655c72800",
      "dbacf9c3574a41b79c95edb16274a059",
      "1e11e74e7bb445769b76a8980a1f2280",
      "85e0fe5df5844140a096d3a13ac5331b",
      "efb1969021d942d3918bab5fcfe52fe4",
      "4e49fe26063947d486deb698fab3d09f",
      "dfa4c229e57a43dcb874912adee7b234",
      "99ecbaf0860c4ac9a55b7da838878dae",
      "1f7c675203184cba92d969997a640505",
      "21edc066d5514058a4a204680664e155",
      "5f258855e8ca493aa7fce7026b82b4fd",
      "052c260063c648eaab040335f00d30d2",
      "83c147b8e86e478fb800fd353b67c7d8",
      "5897211d3d594128a25bf258ad19aad2",
      "950dd0b09ba24402a095fe5e041dc4b4",
      "ab062026e4a54db4970b06a92bddbec9",
      "0db13ea202f34d4796a77ee44f402ea9",
      "a41e2f1eac7a40b8acd45ae04f08acc5",
      "8028775bd8af4f0a8c0cfb186fb02137",
      "ca16fde686b74072a4fd4eba418ba3fa",
      "f839bf14b7d94a19a805cd23496c5858",
      "8d6f073d6f54422697af2b4af8b1b7ab",
      "e2115f8279d84c27b8d17dd67d2f9e5a",
      "5bf77eb9eb1f4053b2ed953c90aeafb9",
      "9da651c5249a44e1858b89b417450703",
      "5c86f6199dbc429f9d7e814a54862ac3",
      "e133d2197c8f4f55a80026ea073a816c",
      "67731197f46949d58a281c3b85c6cfde",
      "2130498ceb1e45c8937fa54dfdb6f6bc",
      "c7235290e4684a2caddd5d7bc0d6f999",
      "448ef08cf4ad4214b16744aec80c90f6",
      "338894c9b01d4d238998040c72a14b03",
      "616e32f7f14841e38ae142cdfd3bc7fa",
      "254c0c19d14341bba5c0300307b00628",
      "1b66cd20649d457c95446f4e2e25593c",
      "6f38a4df3d614053a59e1197eab74844",
      "c1ce6509eb3341d7a9fdc6032a1b58d8",
      "deb3fbd95eb14b81b69ba76df8cc85d1",
      "088b4965e4784be6afa499b8a74fe275",
      "af788d85178c4c59ab7509acd4ffdcc6",
      "e5b4fa646a0b4eeba32594757cd31a46",
      "a785fce223294b64823d3dd9f039de38",
      "f1d047761e164d35ab94216f111d8f43",
      "34e6cd4d934e44f69069140daac9c5f0",
      "6b3289c5bb7b4e9c965952ce3f33228b",
      "6c83ae58fb12469fb7f02a2a2a53da23",
      "b48f950a97b7473f8fb78d811cbaef0e",
      "90cc96e81a3349a5a1cc3fdf4458ce7a",
      "765781cdcd50421db4968b12cd522126",
      "6c7dfaf62b6e4da8807f59d46296e4b0",
      "22cb2bc86cda4bdf8848746cda149591",
      "41f6e8a0661b45389a8ee7a784c008cc",
      "077c12ca57bb46aca9ef9416aa9323e9",
      "29d668516c294805a24a51ce7857e2be",
      "59c3ee1502324ae09e3ae99f6aa29e2c",
      "6fd318c3636b444ab1f605eeab90eb0d",
      "675735ac82144f328c3db4ece4e28a43",
      "cabf1a87e1f64db196b8265028fd0773",
      "a1c8dc62a91c4bd18983dbc8dcfd4bc6",
      "f00f1a2e108543e9a2bd987be156a705",
      "d0315ad7035f41b2af968fc7f472dd7d",
      "fa12a22185c14e66ab4ef545fc9a96a3",
      "77c685fba7c24d6eb5d6521378bcaecf",
      "0cb6e6b4a8a2427f9539ea892a8fbb81",
      "1b4ddb0457ab4156940f5d0b4a28a039",
      "4e27f6b19e3c488d8d5eadb47117585c",
      "54a5bffaa75c4db5b4c71812e13b2c32",
      "d1af9bf8035d42179ee563b2a4217ecc",
      "dd032f468d964f83a8aa1ea6a9249656",
      "adf78252327640a88e2c4e9ae54acae2",
      "be6d4d050abf441c83ef5818be3fcc7d",
      "3264549c3de5436580c5c8827dc16fd8",
      "5b92a9ece8ed45f293002d9643705212",
      "c082239fb6c34a9198dea7c09ff66e80",
      "439fee98f7294fb1ae2b84d2039ac651",
      "27eccddc64f44f8eaac12ac69a89b92b",
      "610675d930e749218ac9934132dab591",
      "a8b4ae262ce44050b272175b379e86f4",
      "f814f590d34f4f97874958b727753581",
      "b1dce7c287aa4e228d3df8f0d785a825",
      "d309259d096c4ec8a6f3623852b8e171",
      "7e7ab6a573ce456c844a507acb393bd4",
      "62775b9f97814f6982b89764e648bf22",
      "a5afa3a31c02434aabb4564f4809eb31",
      "76c5a7a4768649a2a632b3643a695e0b",
      "5dd0631c917a400d86d7201da23037a6",
      "eebecaad2d8647af9fd3d5ec29b4844b",
      "7b07f494a34c42129af6037b9d35f3b9",
      "67bd09f6e6e447f7a6bdc53758e212ac",
      "e457034e6872478680f3ea10c307f2f9",
      "cb65a27304874d8aa3c9d7d076382108",
      "223cf3ebdfde4d1f8cb76b582537b729",
      "8f1c44a498ee41e4a6e00f7b56027808",
      "4477af8c19fa473cb49b7cba7d0d0c75",
      "598641b092c1471e94d53f166469cf58",
      "2ba9abbdaa1e4594b2e620c0aa09940a",
      "1e9f9d0d05fa493ca34440bd979594b9",
      "d7a65b1d3938456b8528d6ad37542b9d",
      "f8d865bd9cd140c6985553730b3142f0",
      "fb360a10b2054c8f8ba8908a823a7e6c",
      "4b93f32a3a374ad68333d6fe5844a7df",
      "536f8866321641bdb98f5a8a002dc276",
      "73a3be20cc0a44b5959176e78208a38f",
      "2e9b13103de54306b94b3e539bade110",
      "74b0086f0a5c4c37852f2034792fab9d",
      "3edc0066c65c48b387cb6bcb34423680",
      "593fb574bb0b4c57817f80fdae711978",
      "eaafb7842185404c990cb9a55ef1b677",
      "29d26939b9454b1e8cef8bb4501e04bd",
      "9ff6857636fe49f48d04f408f639d26a",
      "afee7e3c03a64f29ab7a4367fa98e3c7",
      "e794528a0b874d1db65458fa54f8d8a4",
      "d7dcb9ecf70540a68d8fd92937808246",
      "84bfc13b83a945d699068d1f6ab3d0fe",
      "a974ba7810f14c43a8ece7b6bc76db18",
      "c11b5e111e7043049cc3240466c0913a",
      "29678e9f511a420583b406c5a5780dd5",
      "2454278da9844850bf6e34e152d37d41",
      "03f8386491834e5bbdcfdac4a1de6a9b",
      "350ce21a8ee74f5e9eb4824f027f5c94",
      "a17a159b66824d10ba7489b54488f28e",
      "58d0347524aa4ebcb8049bd36d2ab5de"
     ]
    },
    "id": "oKpm8kN2nZVY",
    "outputId": "45478a59-9003-493e-8132-edf06cb83baa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32075235f0b747c5847ba5572cf46919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baab8e137804d22a32cf250199eb9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd5d143481545c9bbd775be99c7cf21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbacf9c3574a41b79c95edb16274a059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c147b8e86e478fb800fd353b67c7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf77eb9eb1f4053b2ed953c90aeafb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b66cd20649d457c95446f4e2e25593c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c83ae58fb12469fb7f02a2a2a53da23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675735ac82144f328c3db4ece4e28a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1af9bf8035d42179ee563b2a4217ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f814f590d34f4f97874958b727753581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e457034e6872478680f3ea10c307f2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b93f32a3a374ad68333d6fe5844a7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e794528a0b874d1db65458fa54f8d8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started on GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mareebaa9999\u001b[0m (\u001b[33mareebaa9999-devex\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251229_152205-qem4pvv7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/areebaa9999-devex/huggingface/runs/qem4pvv7' target=\"_blank\">upbeat-elevator-3</a></strong> to <a href='https://wandb.ai/areebaa9999-devex/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/areebaa9999-devex/huggingface' target=\"_blank\">https://wandb.ai/areebaa9999-devex/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/areebaa9999-devex/huggingface/runs/qem4pvv7' target=\"_blank\">https://wandb.ai/areebaa9999-devex/huggingface/runs/qem4pvv7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 02:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.453900</td>\n",
       "      <td>0.389141</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.892781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.261300</td>\n",
       "      <td>0.392632</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.896138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# 1. Install necessary libraries (Run once)\n",
    "!pip install -q transformers[torch] datasets evaluate accelerate scikit-learn\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# Clear GPU cache to prevent memory errors\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# --- STEP 1: TOKENIZE AND PREPROCESS ---\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Using max_length=128 instead of 512 to save memory and speed up training\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Smaller subsets to ensure stability on free-tier Colab\n",
    "# 5000 train and 500 test samples is enough to demonstrate fine-tuning for Task 1\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(5000))\n",
    "test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(500))\n",
    "\n",
    "# --- STEP 2: FINE-TUNE BERT ---\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=4)\n",
    "\n",
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = metric_acc.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    f1 = metric_f1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "# Optimized Training Arguments for Colab T4 GPU\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",        # Corrected for Transformers v4.46+\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8, # Reduced from 16 to 8 to prevent memory crash\n",
    "    per_device_eval_batch_size=8,  # Reduced from 16 to 8\n",
    "    num_train_epochs=2,            # 2 epochs is sufficient for a news classifier\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    fp16=True,                     # USE MIXED PRECISION: This stops crashes and doubles speed\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start Training\n",
    "print(\"Training started on GPU...\")\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./news_classifier_bert\")\n",
    "tokenizer.save_pretrained(\"./news_classifier_bert\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_Kpxnfetiwm"
   },
   "source": [
    "## Deploy using Gradio for Live Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "id": "apQ1k8fmtkNR",
    "outputId": "06a15d3f-4234-4d5f-d2c1-8e7e56f3f71d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://47212c2f62f1ea0e9e.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://47212c2f62f1ea0e9e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model_path = \"./news_classifier_bert\"\n",
    "classifier = pipeline(\"text-classification\", model=model_path, tokenizer=model_path)\n",
    "\n",
    "# Label Mapping for AG News\n",
    "labels = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "\n",
    "def predict_news_topic(headline):\n",
    "    result = classifier(headline)[0]\n",
    "    # Extract label index (e.g., 'LABEL_1') and map to string\n",
    "    label_idx = int(result['label'].split('_')[1])\n",
    "    return f\"Topic: {labels[label_idx]} (Confidence: {result['score']:.2f})\"\n",
    "\n",
    "# Create Gradio Interface\n",
    "interface = gr.Interface(\n",
    "    fn=predict_news_topic,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Enter news headline here...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"News Topic Classifier (BERT)\",\n",
    "    description=\"Enter a news headline to classify it into World, Sports, Business, or Sci/Tech.\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    interface.launch()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
